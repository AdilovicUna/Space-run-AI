\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

In conclusion, this thesis has investigated the efficacy of different reinforcement learning algorithms in various environments in a game implemented in the Godot game engine. The results showed that the \texttt{ExpectedSARSA} algorithm performed moderately or exedingly well in all environments, while the performance of other algorithms varied. In particular, \texttt{MonteCarlo} demonstrated impressive results in environments featuring bug and virus obstacles. All algorithms displayed adequate performance in environments with individual trap types, while performance in environments with multiple obstacle types was not as consistent. The results underscore the importance of the random actions that the agent receives during training and the balance between exploration and exploitation in reinforcement learning. Future research could explore ways to influence these random actions to potentially achieve better outcomes.